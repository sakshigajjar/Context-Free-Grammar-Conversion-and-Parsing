{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2v_EXl3mgMWp"
      },
      "outputs": [],
      "source": [
        "STACK = \"Z0\"\n",
        "EPSILON = \"ε\"\n",
        "DELTA = \"𝛿\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "from collections import defaultdict,deque"
      ],
      "metadata": {
        "id": "EKUG5aFrlqki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class State:\n",
        "    name = \"\"\n",
        "    transitions = []\n",
        "    isInitial = False\n",
        "    isFinal = False\n",
        "\n",
        "    def __init__(self, name, isInitial, isFinal, transitions):\n",
        "        self.name = name\n",
        "        self.isInitial = isInitial\n",
        "        self.isFinal = isFinal\n",
        "        self.transitions = transitions\n",
        "\n",
        "    def addTransition(self, transition):\n",
        "        self.transitions.add(transition)\n",
        "\n",
        "    def setFinal (self, isFinal):\n",
        "        self.isFinal = isFinal\n",
        "\n",
        "    def setInitial (self, isInitial):\n",
        "        self.isInitial = isInitial\n",
        "\n",
        "    def __str__(self):\n",
        "        string = self.name\n",
        "        return string"
      ],
      "metadata": {
        "id": "x4hk_kF0gRoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transition:\n",
        "    inputSymbol = ''\n",
        "    currState = ''\n",
        "    nextState = ''\n",
        "    popSymbol = ''\n",
        "    pushSymbols = []\n",
        "\n",
        "    def __init__(self, inputSymbol, currState, nextState, popSymbol, pushSymbols):\n",
        "        self.inputSymbol = inputSymbol\n",
        "        self.currState = currState\n",
        "        self.nextState = nextState\n",
        "        self.popSymbol = popSymbol\n",
        "        self.pushSymbols = pushSymbols\n",
        "\n",
        "    def addPushSymbol(self, sym):\n",
        "        self.pushSymbols.add(sym)\n",
        "\n",
        "    def __str__(self):\n",
        "        pushString = ''.join(self.pushSymbols)\n",
        "        string = self.inputSymbol + \", \" + self.popSymbol + \", \" + pushString\n",
        "        return string\n"
      ],
      "metadata": {
        "id": "816nSL0cgaFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IllegalVariableException(Exception):\n",
        "    def __init__(self, character, rule):\n",
        "        self.st1 = \"Illegal character not in states or terminals\"\n",
        "        self.st2 = character + \" in \" + rule\n",
        "    def __str__(self):\n",
        "        string =  self.st1 + '\\n' + self.st2\n",
        "        return string"
      ],
      "metadata": {
        "id": "c2VwURmGghhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inputGrammar (data):\n",
        "    transitions = []\n",
        "    initStateSym = data[0].rstrip()\n",
        "\n",
        "    terminals = data[1].rstrip()\n",
        "\n",
        "    initState = State(\"Q0\", True, False, [])\n",
        "    midState = State(\"Q1\", False, False, [])\n",
        "    #finalState = State(\"Q2\", False, True, [])\n",
        "\n",
        "    terminals = terminals.split(',')\n",
        "    init = Transition(EPSILON, initState, midState, STACK, [initStateSym, STACK])\n",
        "    transitions.append(init)\n",
        "    for idx in range(2, data.__len__()):\n",
        "        rule = data[idx].strip()\n",
        "        rule = rule.replace(\" \", \"\")\n",
        "        for character in rule:\n",
        "            if character == '-' or character == '>' or character == '|':\n",
        "                pass\n",
        "            elif character not in terminals and (not character.isupper()) and character != LAMBDA:\n",
        "                raise IllegalVariableException(character, rule)\n",
        "\n",
        "        #left hand side: state\n",
        "        lhs = rule[:rule.find('-')]\n",
        "        #right hand side: productions\n",
        "        rhs = rule[rule.find('>') + 1:]\n",
        "        #split productions\n",
        "        rhs = rhs.split('|')\n",
        "        #assign productions to each state\n",
        "        for t in rhs:\n",
        "            trans = Transition(\n",
        "                EPSILON, #terminal\n",
        "                midState,\n",
        "                midState,\n",
        "                lhs, #pop rule symbol on transition\n",
        "                list(t)\n",
        "            )\n",
        "            transitions.append(trans)\n",
        "    for t in terminals:\n",
        "        trans = Transition(\n",
        "            t, #terminal\n",
        "            midState,\n",
        "            midState,\n",
        "            t, #pop rule symbol on transition\n",
        "            EPSILON\n",
        "        )\n",
        "        transitions.append(trans)\n",
        "\n",
        "    states = [initState, midState]\n",
        "    return states, transitions"
      ],
      "metadata": {
        "id": "2dwMrs7qQtIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Automaton:\n",
        "    def __init__(self, states, transitions):\n",
        "        self.states = states\n",
        "        self.transitions = transitions\n",
        "\n",
        "    def toPda(self):\n",
        "        trFunc = {}\n",
        "        print(\"PDA Transitions:\")\n",
        "        for t in self.transitions:\n",
        "            key = (t.currState, t.inputSymbol, t.popSymbol)\n",
        "\n",
        "            if (not key in trFunc.keys()):\n",
        "                trFunc[key] = []\n",
        "            trFunc[key].append((t.nextState, t.pushSymbols))\n",
        "        trFunc = enumerate(trFunc.items())\n",
        "        for i, (key, value) in trFunc:\n",
        "            print(DELTA + '(' + str(key[0]) + ','\n",
        "            + key[1] + ',' + key[2] + ') = {', end=\"\")\n",
        "            targets = []\n",
        "            for val in value:\n",
        "                pushStr = ''.join(val[1])\n",
        "                targets.append(\n",
        "                    '(' + str(val[0]) + ',' + pushStr + ')'\n",
        "                )\n",
        "            print(str(', ').join(targets) + ' }')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pd3pvGqrg1su"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "\n",
        "class CYK:\n",
        "    def __init__(self, grammar, startstate):\n",
        "        self.grammar = grammar\n",
        "        self.startstate = startstate\n",
        "\n",
        "    def __getValidCombinations(self, left_collection_set, right_collection_set):\n",
        "        valid_combinations = []\n",
        "        for num_collection, left_collection in enumerate(left_collection_set):\n",
        "            right_collection = right_collection_set[num_collection]\n",
        "            for left_item in left_collection:\n",
        "                for right_item in right_collection:\n",
        "                    combination = left_item + right_item\n",
        "                    for key, value in self.grammar.items():\n",
        "                        if combination in value:\n",
        "                            if not key in valid_combinations:\n",
        "                                valid_combinations.append(key)\n",
        "        return valid_combinations\n",
        "\n",
        "    def __getCollectionSets(self, full_table, x_position, x_offset):\n",
        "        table_segment = []\n",
        "        y_position = 0\n",
        "        while x_offset >= 2:\n",
        "            item_set = full_table[y_position][x_position:x_position+x_offset]\n",
        "            if x_offset > len(item_set):\n",
        "                return None\n",
        "            table_segment.append(item_set)\n",
        "            x_offset -= 1\n",
        "            y_position += 1\n",
        "        vertical_combinations = []\n",
        "        horizontal_combinations = []\n",
        "        for item in table_segment:\n",
        "            vertical_combinations.append(item[0])\n",
        "            horizontal_combinations.append(item[-1])\n",
        "        return vertical_combinations[::-1], horizontal_combinations\n",
        "\n",
        "    def __generateTable(self, word):\n",
        "        table = [[]]\n",
        "        for letter in word:\n",
        "            valid_states = []\n",
        "            for key, value in self.grammar.items():\n",
        "                if letter in value:\n",
        "                    valid_states.append(key)\n",
        "            table[0].append(valid_states)\n",
        "        for x_offset in range(2,len(word)+1):\n",
        "            table.append([])\n",
        "            for x_position in range(len(word)):\n",
        "                collection_sets = self.__getCollectionSets(table, x_position, x_offset)\n",
        "                if collection_sets:\n",
        "                    table[-1].append(self.__getValidCombinations(*collection_sets))\n",
        "\n",
        "        return table\n",
        "\n",
        "    def checkWord(self, word):\n",
        "        return self.startstate in self.__generateTable(word)[-1][-1]\n",
        "\n",
        "    def outputTable(self, word):\n",
        "        table = self.__generateTable(word)\n",
        "        pretty_table = [\n",
        "            [\n",
        "                \",\".join(sorted(y)) if y != [] else u\"\\u2205\" for y in x\n",
        "            ] for x in table\n",
        "        ]\n",
        "\n",
        "        print(tabulate(pretty_table, list(word), tablefmt=\"grid\"))"
      ],
      "metadata": {
        "id": "Xhq8NmLcuDoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_nullable_rules(data):\n",
        "    rules = defaultdict(list)\n",
        "    initial_state_sym = data[0].strip()\n",
        "    terminals = data[1].strip().split(',')\n",
        "\n",
        "\n",
        "    for idx in range(2, len(data)):\n",
        "        rule = data[idx].strip()\n",
        "        lhs, rhs = rule.split('->')\n",
        "        productions = rhs.split('|')\n",
        "        for production in productions:\n",
        "            rules[lhs].append(production.strip())\n",
        "    dir_nullable = set()\n",
        "\n",
        "\n",
        "    for non_terminal, productions in rules.items():\n",
        "        for production in rules[non_terminal]:\n",
        "            if production == 'ε':\n",
        "                dir_nullable.add(non_terminal)\n",
        "    # Step 1: Identify nullable symbols\n",
        "    nullable = set()\n",
        "    changed = True\n",
        "    while changed:\n",
        "        changed = False\n",
        "        for non_terminal, productions in rules.items():\n",
        "            if non_terminal not in nullable:\n",
        "                for production in productions:\n",
        "                    # Check if the production is ε or all symbols are nullable\n",
        "                    if production == EPSILON or all(symbol in nullable for symbol in production):\n",
        "                        nullable.add(non_terminal)\n",
        "                        changed = True\n",
        "\n",
        "    # Step 2: Generate new productions by removing nullable symbols\n",
        "    new_rules = defaultdict(list)\n",
        "    for non_terminal, productions in rules.items():\n",
        "        for production in productions:\n",
        "            # Include original production\n",
        "            new_rules[non_terminal].append(production)\n",
        "\n",
        "            # Generate new productions by removing nullable symbols\n",
        "            nullable_positions = [i for i, symbol in enumerate(production) if symbol in nullable]\n",
        "\n",
        "            # Iterate through combinations of nullable positions\n",
        "            for mask in range(1, len(nullable_positions) + 1):\n",
        "                for combination in itertools.combinations(nullable_positions, mask):\n",
        "                    new_production = ''.join([production[i] for i in range(len(production)) if i not in combination])\n",
        "                    if new_production and new_production not in new_rules[non_terminal]:\n",
        "                        new_rules[non_terminal].append(new_production)\n",
        "\n",
        "    # Step 3: Construct the final rules\n",
        "    final_rules = defaultdict(list)\n",
        "    for non_terminal, productions in new_rules.items():\n",
        "        for production in productions:\n",
        "            if production != EPSILON:\n",
        "                if len(production)==1 and (production in dir_nullable):\n",
        "                    if(non_terminal==initial_state_sym ):\n",
        "                        final_rules[non_terminal].append(EPSILON)\n",
        "                    else:\n",
        "                      pass\n",
        "                else:\n",
        "                    final_rules[non_terminal].append(production)\n",
        "            elif production == EPSILON and non_terminal==initial_state_sym:\n",
        "                final_rules[non_terminal].append(EPSILON)\n",
        "\n",
        "    # Print the final rules\n",
        "    print(\"Modified Grammar after removing nullable rules:\")\n",
        "    for non_terminal, productions in final_rules.items():\n",
        "        print(f\"{non_terminal} -> {'|'.join(productions)}\")\n",
        "\n",
        "    return final_rules"
      ],
      "metadata": {
        "id": "p_9TNOkGlxEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_unit_productions(rules, initial_state_sym):\n",
        "    def resolve_unit_productions():\n",
        "\n",
        "        queue = deque()\n",
        "        for non_terminal in rules:\n",
        "            queue.append(non_terminal)\n",
        "\n",
        "        while queue:\n",
        "            lhs = queue.popleft()\n",
        "            productions = rules[lhs]\n",
        "            new_productions = set()\n",
        "\n",
        "            for production in productions:\n",
        "                # Check if the production is a unit production (A -> B)\n",
        "                if len(production) == 1 and production.isupper():\n",
        "                    unit_nt = production\n",
        "                    # Add the productions of the unit non-terminal (B) to lhs (A)\n",
        "                    for prod in rules[unit_nt]:\n",
        "                        if prod not in new_productions:\n",
        "                            new_productions.add(prod)\n",
        "                            queue.append(lhs)\n",
        "                else:\n",
        "                    # Add the non-unit production to the new set\n",
        "                    new_productions.add(production)\n",
        "\n",
        "\n",
        "            rules[lhs] = list(new_productions)\n",
        "\n",
        "    # Resolve unit productions\n",
        "    resolve_unit_productions()\n",
        "\n",
        "    # Print the final CFG\n",
        "    final_rules = defaultdict(list)\n",
        "    for non_terminal, productions in rules.items():\n",
        "        for production in productions:\n",
        "            if len(production) != 1 or production == initial_state_sym or not production.isupper():\n",
        "                final_rules[non_terminal].append(production)\n",
        "\n",
        "        # Remove duplicates\n",
        "        final_rules[non_terminal] = list(set(final_rules[non_terminal]))\n",
        "\n",
        "    print(\"Modified Grammar after removing unit productions:\")\n",
        "    for non_terminal, productions in final_rules.items():\n",
        "        print(f\"{non_terminal} -> {'|'.join(productions)}\")\n",
        "\n",
        "    return final_rules\n"
      ],
      "metadata": {
        "id": "Zd0reyuvl2GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_rhs(rules, initial_state_sym,terminals):\n",
        "\n",
        "    cnf_rules = defaultdict(list)\n",
        "    fresh_nt_count = 0\n",
        "\n",
        "    # def fresh_nt():\n",
        "    #     nonlocal fresh_nt_count\n",
        "    #     fresh_nt_count += 1\n",
        "    #     return f'X{fresh_nt_count}'\n",
        "    def fresh_nt():\n",
        "        nonlocal fresh_nt_count\n",
        "        fresh_nt_count += 1\n",
        "        apostrophes = \"'\" * fresh_nt_count\n",
        "        return f'X{apostrophes}'\n",
        "\n",
        "\n",
        "    # Step 1: Handle productions with mixed terminals and non-terminals\n",
        "    for lhs, productions in rules.items():\n",
        "      for production in productions:\n",
        "        current_production = []\n",
        "        if len(production) > 1:\n",
        "            for symbol in production:\n",
        "                if symbol in terminals:\n",
        "                    # Check if the terminal already has a corresponding non-terminal\n",
        "                    existing_nt = None\n",
        "                    for nt, prod_list in cnf_rules.items():\n",
        "                        if len(prod_list) == 1 and prod_list[0] == symbol:\n",
        "                            existing_nt = nt\n",
        "                            break\n",
        "\n",
        "                    if existing_nt:\n",
        "                        # If the terminal already has a corresponding non-terminal, use it\n",
        "                        current_production.append(existing_nt)\n",
        "                    else:\n",
        "                        # Create a new non-terminal for the terminal\n",
        "                        new_nt = fresh_nt()\n",
        "                        cnf_rules[new_nt].append(symbol)\n",
        "                        current_production.append(new_nt)\n",
        "                else:\n",
        "                    current_production.append(symbol)\n",
        "\n",
        "            # Append the current production to the CNF rules for the current lhs\n",
        "            cnf_rules[lhs].append(''.join(current_production))\n",
        "        else:\n",
        "          cnf_rules[lhs].append(production)\n",
        "\n",
        "\n",
        "    # Print the final CFG in CNF\n",
        "    print(\"Modified Grammar after restricting rhs with only non-terminals or single terminal:\")\n",
        "    for lhs, productions in cnf_rules.items():\n",
        "        print(f\"{lhs} -> {'|'.join(productions)}\")\n",
        "\n",
        "    return cnf_rules\n"
      ],
      "metadata": {
        "id": "CnTY2tD9l80j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_productions_length(rules):\n",
        "    def fresh_nt(non_t):\n",
        "        nonlocal fresh_nt_count\n",
        "        fresh_nt_count += 1\n",
        "        apostrophes = \"'\" * fresh_nt_count\n",
        "        return f'{non_t}{apostrophes}'\n",
        "\n",
        "    def custom_len(s: str) -> int:\n",
        "        count = 0\n",
        "        i = 0\n",
        "        length = len(s)\n",
        "\n",
        "        while i < length:\n",
        "            if s[i] == \"'\":\n",
        "                while i < length and s[i] == \"'\":\n",
        "                    i += 1\n",
        "            else:\n",
        "                count += 1\n",
        "                i += 1\n",
        "\n",
        "        return count\n",
        "\n",
        "    def parse_production(production):\n",
        "        symbols = []\n",
        "        i = 0\n",
        "        length = len(production)\n",
        "        while i < length:\n",
        "            if production[i] == \"'\":\n",
        "                start = i - 1\n",
        "                while i < length and production[i] == \"'\":\n",
        "                    i += 1\n",
        "                symbols.append(production[start:i])\n",
        "            elif  i!=length-1 and production[i+1]!=\"'\":\n",
        "                symbols.append(production[i])\n",
        "                i += 1\n",
        "            elif i==length-1:\n",
        "                symbols.append(production[i])\n",
        "                i += 1\n",
        "            else:\n",
        "                i+=1\n",
        "        return symbols\n",
        "\n",
        "    cnf_rules = defaultdict(list)\n",
        "    fresh_nt_count = 0\n",
        "    rule_map = {}\n",
        "\n",
        "    for lhs, productions in rules.items():\n",
        "        fresh_nt_count = 0\n",
        "        for production in productions:\n",
        "            if custom_len(production) <= 2:\n",
        "                cnf_rules[lhs].append(production)\n",
        "                continue\n",
        "\n",
        "            current_symbols = parse_production(production)\n",
        "            #print(current_symbols)\n",
        "            while custom_len(''.join(current_symbols)) > 2:\n",
        "                # Parse production and handle multi-character non-terminals\n",
        "                first, second = current_symbols[:2]\n",
        "                rule_key = (first, second)\n",
        "\n",
        "                if rule_key not in rule_map:\n",
        "                    new_nt = fresh_nt(lhs)\n",
        "                    cnf_rules[new_nt].append(first + second)\n",
        "                    rule_map[rule_key] = new_nt\n",
        "                else:\n",
        "                    new_nt = rule_map[rule_key]\n",
        "\n",
        "                current_symbols = [new_nt] + current_symbols[2:]\n",
        "\n",
        "            if custom_len(''.join(current_symbols)) == 2:\n",
        "                cnf_rules[lhs].append(''.join(current_symbols))\n",
        "\n",
        "    print(\"Modified grammar after converting to the form A->BC|a:\")\n",
        "    for lhs, productions in cnf_rules.items():\n",
        "        print(f\"{lhs} -> {'|'.join(productions)}\")\n",
        "\n",
        "    return cnf_rules\n"
      ],
      "metadata": {
        "id": "G3czkULBmCNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cfgtocnf(data):\n",
        "    initial_state_sym = data[0].strip()\n",
        "    terminals = data[1].strip().split(',')\n",
        "    r1=remove_nullable_rules(data)\n",
        "    r2=remove_unit_productions(r1, initial_state_sym)\n",
        "    r3=process_rhs(r2, initial_state_sym,terminals)\n",
        "    r4=convert_productions_length(r3)\n",
        "    return r4"
      ],
      "metadata": {
        "id": "JRn8OS4omNpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # print(\"Enter the CFG input (type 'end' when you are done):\")\n",
        "    # lines = []\n",
        "    # while True:\n",
        "    #     line = input().strip()\n",
        "    #     if line.lower() == 'end':\n",
        "    #         break\n",
        "    #     lines.append(line)\n",
        "    lines=[\"S\", \"a,b,ε\", \"S->aAB|BC\", \"A->aBA|a\", \"B->aCC|b\", \"C->aAB|a\"]\n",
        "    states, transitions = inputGrammar(lines)\n",
        "\n",
        "    pda = Automaton(states, transitions)\n",
        "    pda.toPda()\n",
        "\n",
        "    print(\" \")\n",
        "    print(\"First Converting cfg to cnf first\")\n",
        "    print(\" \")\n",
        "    cnf=cfgtocnf(lines)\n",
        "\n",
        "    while(True):\n",
        "        print(\"Parse targets? (Y/N)\")\n",
        "        inp = input().strip().capitalize()\n",
        "        if (inp != \"Y\"): break\n",
        "        word = input(\"String to parse: \").strip()\n",
        "        cyk = CYK(cnf, lines[0])\n",
        "        print(cyk.checkWord(word))\n",
        "        cyk.outputTable(word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvPLcyjNQm_H",
        "outputId": "491533be-6765-4568-9a21-5b95428b063b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PDA Transitions:\n",
            "𝛿(Q0,ε,Z0) = {(Q1,SZ0) }\n",
            "𝛿(Q1,ε,S) = {(Q1,aAB), (Q1,BC) }\n",
            "𝛿(Q1,ε,A) = {(Q1,aBA), (Q1,a) }\n",
            "𝛿(Q1,ε,B) = {(Q1,aCC), (Q1,b) }\n",
            "𝛿(Q1,ε,C) = {(Q1,aAB), (Q1,a) }\n",
            "𝛿(Q1,a,a) = {(Q1,ε) }\n",
            "𝛿(Q1,b,b) = {(Q1,ε) }\n",
            "𝛿(Q1,ε,ε) = {(Q1,ε) }\n",
            "Parse targets? (Y/N)\n",
            "Y\n",
            "String to parse: abbaaa\n",
            " \n",
            "First Converting cfg to cnf first\n",
            " \n",
            "Modified Grammar after removing nullable rules:\n",
            "S -> aAB|BC\n",
            "A -> aBA|a\n",
            "B -> aCC|b\n",
            "C -> aAB|a\n",
            "Modified Grammar after removing unit productions:\n",
            "S -> BC|aAB\n",
            "A -> a|aBA\n",
            "B -> aCC|b\n",
            "C -> a|aAB\n",
            "Modified Grammar after restricting rhs with only non-terminals or single terminal:\n",
            "S -> BC|X'AB\n",
            "X' -> a\n",
            "A -> a|X'BA\n",
            "B -> X'CC|b\n",
            "C -> a|X'AB\n",
            "Modified grammar after converting to the form A->BC|a:\n",
            "S -> BC|S'B\n",
            "S' -> X'A\n",
            "X' -> a\n",
            "A -> a|A'A\n",
            "A' -> X'B\n",
            "B' -> X'C\n",
            "B -> B'C|b\n",
            "C -> a|S'B\n",
            "False\n",
            "+--------+-----+-----+--------+--------+--------+\n",
            "| a      | b   | b   | a      | a      | a      |\n",
            "+========+=====+=====+========+========+========+\n",
            "| A,C,X' | B   | B   | A,C,X' | A,C,X' | A,C,X' |\n",
            "+--------+-----+-----+--------+--------+--------+\n",
            "| A'     | ∅   | S   | B',S'  | B',S'  |        |\n",
            "+--------+-----+-----+--------+--------+--------+\n",
            "| ∅      | ∅   | ∅   | B      |        |        |\n",
            "+--------+-----+-----+--------+--------+--------+\n",
            "| ∅      | ∅   | ∅   |        |        |        |\n",
            "+--------+-----+-----+--------+--------+--------+\n",
            "| ∅      | ∅   |     |        |        |        |\n",
            "+--------+-----+-----+--------+--------+--------+\n",
            "| ∅      |     |     |        |        |        |\n",
            "+--------+-----+-----+--------+--------+--------+\n",
            "Parse targets? (Y/N)\n",
            "Y\n",
            "String to parse: aab\n",
            " \n",
            "First Converting cfg to cnf first\n",
            " \n",
            "Modified Grammar after removing nullable rules:\n",
            "S -> aAB|BC\n",
            "A -> aBA|a\n",
            "B -> aCC|b\n",
            "C -> aAB|a\n",
            "Modified Grammar after removing unit productions:\n",
            "S -> BC|aAB\n",
            "A -> a|aBA\n",
            "B -> aCC|b\n",
            "C -> a|aAB\n",
            "Modified Grammar after restricting rhs with only non-terminals or single terminal:\n",
            "S -> BC|X'AB\n",
            "X' -> a\n",
            "A -> a|X'BA\n",
            "B -> X'CC|b\n",
            "C -> a|X'AB\n",
            "Modified grammar after converting to the form A->BC|a:\n",
            "S -> BC|S'B\n",
            "S' -> X'A\n",
            "X' -> a\n",
            "A -> a|A'A\n",
            "A' -> X'B\n",
            "B' -> X'C\n",
            "B -> B'C|b\n",
            "C -> a|S'B\n",
            "True\n",
            "+--------+--------+-----+\n",
            "| a      | a      | b   |\n",
            "+========+========+=====+\n",
            "| A,C,X' | A,C,X' | B   |\n",
            "+--------+--------+-----+\n",
            "| B',S'  | A'     |     |\n",
            "+--------+--------+-----+\n",
            "| C,S    |        |     |\n",
            "+--------+--------+-----+\n",
            "Parse targets? (Y/N)\n",
            "Y\n",
            "String to parse: ba\n",
            " \n",
            "First Converting cfg to cnf first\n",
            " \n",
            "Modified Grammar after removing nullable rules:\n",
            "S -> aAB|BC\n",
            "A -> aBA|a\n",
            "B -> aCC|b\n",
            "C -> aAB|a\n",
            "Modified Grammar after removing unit productions:\n",
            "S -> BC|aAB\n",
            "A -> a|aBA\n",
            "B -> aCC|b\n",
            "C -> a|aAB\n",
            "Modified Grammar after restricting rhs with only non-terminals or single terminal:\n",
            "S -> BC|X'AB\n",
            "X' -> a\n",
            "A -> a|X'BA\n",
            "B -> X'CC|b\n",
            "C -> a|X'AB\n",
            "Modified grammar after converting to the form A->BC|a:\n",
            "S -> BC|S'B\n",
            "S' -> X'A\n",
            "X' -> a\n",
            "A -> a|A'A\n",
            "A' -> X'B\n",
            "B' -> X'C\n",
            "B -> B'C|b\n",
            "C -> a|S'B\n",
            "True\n",
            "+-----+--------+\n",
            "| b   | a      |\n",
            "+=====+========+\n",
            "| B   | A,C,X' |\n",
            "+-----+--------+\n",
            "| S   |        |\n",
            "+-----+--------+\n",
            "Parse targets? (Y/N)\n",
            "Y\n",
            "String to parse: baab\n",
            " \n",
            "First Converting cfg to cnf first\n",
            " \n",
            "Modified Grammar after removing nullable rules:\n",
            "S -> aAB|BC\n",
            "A -> aBA|a\n",
            "B -> aCC|b\n",
            "C -> aAB|a\n",
            "Modified Grammar after removing unit productions:\n",
            "S -> BC|aAB\n",
            "A -> a|aBA\n",
            "B -> aCC|b\n",
            "C -> a|aAB\n",
            "Modified Grammar after restricting rhs with only non-terminals or single terminal:\n",
            "S -> BC|X'AB\n",
            "X' -> a\n",
            "A -> a|X'BA\n",
            "B -> X'CC|b\n",
            "C -> a|X'AB\n",
            "Modified grammar after converting to the form A->BC|a:\n",
            "S -> BC|S'B\n",
            "S' -> X'A\n",
            "X' -> a\n",
            "A -> a|A'A\n",
            "A' -> X'B\n",
            "B' -> X'C\n",
            "B -> B'C|b\n",
            "C -> a|S'B\n",
            "True\n",
            "+-----+--------+--------+-----+\n",
            "| b   | a      | a      | b   |\n",
            "+=====+========+========+=====+\n",
            "| B   | A,C,X' | A,C,X' | B   |\n",
            "+-----+--------+--------+-----+\n",
            "| S   | B',S'  | A'     |     |\n",
            "+-----+--------+--------+-----+\n",
            "| ∅   | C,S    |        |     |\n",
            "+-----+--------+--------+-----+\n",
            "| S   |        |        |     |\n",
            "+-----+--------+--------+-----+\n",
            "Parse targets? (Y/N)\n",
            "N\n"
          ]
        }
      ]
    }
  ]
}